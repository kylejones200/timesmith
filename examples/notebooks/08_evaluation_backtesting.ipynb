{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Backtesting\n",
    "\n",
    "This notebook demonstrates how to evaluate forecasters using backtesting with time series cross-validation.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Creating forecast tasks\n",
    "- Running backtests with different splitters\n",
    "- Summarizing backtest results\n",
    "- Comparing multiple models\n",
    "- Understanding evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timesmith import (\n",
    "    ForecastTask,\n",
    "    SimpleMovingAverageForecaster,\n",
    "    ExponentialMovingAverageForecaster,\n",
    "    ExponentialSmoothingForecaster,\n",
    "    backtest_forecaster,\n",
    "    summarize_backtest,\n",
    "    compare_models,\n",
    "    ExpandingWindowSplit,\n",
    "    SlidingWindowSplit,\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Evaluation and backtesting tools loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Time Series Data\n",
    "\n",
    "Let's create a realistic time series for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series with trend and seasonality\n",
    "dates = pd.date_range(\"2020-01-01\", periods=200, freq=\"D\")\n",
    "\n",
    "# Trend component\n",
    "trend = np.linspace(100, 150, len(dates))\n",
    "\n",
    "# Seasonal component (weekly pattern)\n",
    "seasonal = 10 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)\n",
    "\n",
    "# Noise\n",
    "noise = np.random.normal(0, 5, len(dates))\n",
    "\n",
    "# Combine\n",
    "y = pd.Series(trend + seasonal + noise, index=dates, name=\"value\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y.index, y.values, linewidth=1.5, alpha=0.7)\n",
    "plt.title(\"Time Series Data for Backtesting\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Data shape: {y.shape}\")\n",
    "print(f\"Date range: {y.index[0]} to {y.index[-1]}\")\n",
    "\n",
    "# Create forecast task\n",
    "task = ForecastTask(y=y, fh=10, frequency=\"D\")\n",
    "print(f\"\\nForecast task created:\")\n",
    "print(f\"  Forecast horizon: {task.fh}\")\n",
    "print(f\"  Frequency: {task.frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run a Simple Backtest\n",
    "\n",
    "Backtesting uses time series cross-validation to evaluate forecasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit forecaster\n",
    "forecaster = SimpleMovingAverageForecaster(window=7)\n",
    "\n",
    "# Run backtest\n",
    "result = backtest_forecaster(forecaster, task)\n",
    "\n",
    "print(\"Backtest Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of folds: {len(result.results)}\")\n",
    "print(f\"\\nFirst few results:\")\n",
    "print(result.results[[\"fold_id\", \"cutoff\", \"mae\", \"rmse\", \"mape\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarize Backtest Results\n",
    "\n",
    "Get aggregate metrics across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize backtest\n",
    "summary = summarize_backtest(result)\n",
    "\n",
    "print(\"Backtest Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nAggregate Metrics:\")\n",
    "for key, value in summary[\"aggregate_metrics\"].items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Expanding Window Split\n",
    "\n",
    "Expanding window uses all historical data up to each cutoff point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding window splitter\n",
    "splitter = ExpandingWindowSplit(initial_window=50, step=10)\n",
    "\n",
    "# Get splits\n",
    "splits = list(splitter.split(y))\n",
    "\n",
    "print(f\"Expanding Window Splits:\")\n",
    "print(f\"  Number of splits: {len(splits)}\")\n",
    "print(f\"\\nFirst 3 splits:\")\n",
    "for i, (train_idx, test_idx) in enumerate(splits[:3]):\n",
    "    print(f\"  Split {i}: train={len(train_idx)}, test={len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sliding Window Split\n",
    "\n",
    "Sliding window uses a fixed-size window that moves forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window splitter\n",
    "sliding_splitter = SlidingWindowSplit(window=50, step=10)\n",
    "\n",
    "# Get splits\n",
    "sliding_splits = list(sliding_splitter.split(y))\n",
    "\n",
    "print(f\"Sliding Window Splits:\")\n",
    "print(f\"  Number of splits: {len(sliding_splits)}\")\n",
    "print(f\"\\nFirst 3 splits:\")\n",
    "for i, (train_idx, test_idx) in enumerate(sliding_splits[:3]):\n",
    "    print(f\"  Split {i}: train={len(train_idx)}, test={len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Multiple Models\n",
    "\n",
    "Compare different forecasters using the same backtest setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple forecasters\n",
    "forecasters = {\n",
    "    \"Simple MA (7)\": SimpleMovingAverageForecaster(window=7),\n",
    "    \"Simple MA (12)\": SimpleMovingAverageForecaster(window=12),\n",
    "    \"Exponential MA\": ExponentialMovingAverageForecaster(alpha=0.3),\n",
    "    \"Exponential Smoothing\": ExponentialSmoothingForecaster(),\n",
    "}\n",
    "\n",
    "# Run comparison\n",
    "comparison = compare_models(forecasters, task, metrics=[\"mae\", \"rmse\", \"mape\"])\n",
    "\n",
    "print(\"Model Comparison Results:\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- How to create forecast tasks for evaluation\n",
    "- How to run backtests with time series cross-validation\n",
    "- How to summarize backtest results with aggregate metrics\n",
    "- How to use expanding and sliding window splits\n",
    "- How to compare multiple models side-by-side\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Backtesting is essential for time series evaluation\n",
    "- Expanding windows use all historical data (more realistic)\n",
    "- Sliding windows use fixed-size windows (more folds)\n",
    "- Always compare multiple models to find the best one"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}