{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation and Backtesting",
        "",
        "This notebook demonstrates how to evaluate forecasters using backtesting."
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "import pandas as pd",
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import timesmith as ts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Forecast Task"
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "# Create time series",
        "dates = pd.date_range('2020-01-01', periods=200, freq='D')",
        "y = pd.Series(np.random.randn(200).cumsum() + 100, index=dates)",
        "",
        "# Create forecast task",
        "task = ts.ForecastTask(y=y, fh=10, frequency='D')",
        "print(f\"Forecast horizon: {task.fh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Backtest"
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "# Create forecaster",
        "forecaster = ts.SimpleMovingAverageForecaster(window=7)",
        "",
        "# Run backtest",
        "result = ts.backtest_forecaster(forecaster, task)",
        "",
        "print(f\"Number of folds: {len(result.fold_results)}\")",
        "print(f\"Metrics computed: {list(result.fold_results[0].metrics.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarizing Results"
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "# Summarize backtest",
        "summary = ts.summarize_backtest(result)",
        "",
        "print(\"Aggregate Metrics:\")",
        "for metric, value in summary['aggregate_metrics'].items():",
        "    print(f\"  {metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expanding Window Split"
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "# Expanding window splitter",
        "splitter = ts.ExpandingWindowSplit(initial_window=50, step=10)",
        "",
        "# Get splits",
        "splits = list(splitter.split(y))",
        "print(f\"Number of splits: {len(splits)}\")",
        "for i, (train_idx, test_idx) in enumerate(splits[:3]):",
        "    print(f\"Split {i}: train={len(train_idx)}, test={len(test_idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sliding Window Split"
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "# Sliding window splitter",
        "sliding_splitter = ts.SlidingWindowSplit(window=50, step=10)",
        "",
        "# Get splits",
        "sliding_splits = list(sliding_splitter.split(y))",
        "print(f\"Number of splits: {len(sliding_splits)}\")",
        "for i, (train_idx, test_idx) in enumerate(sliding_splits[:3]):",
        "    print(f\"Split {i}: train={len(train_idx)}, test={len(test_idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison"
      ]
    },
    {
      "cell_type": "python",
      "metadata": {},
      "source": [
        "# Compare multiple forecasters",
        "forecasters = {",
        "    'MA': ts.SimpleMovingAverageForecaster(window=7),",
        "    'EMA': ts.ExponentialMovingAverageForecaster(alpha=0.3),",
        "    'ES': ts.ExponentialSmoothingForecaster()",
        "}",
        "",
        "# Run comparison",
        "comparison = ts.compare_models(forecasters, task)",
        "",
        "print(\"Model Comparison Results:\")",
        "for model_name, result in comparison.results.items():",
        "    print(f\"\\n{model_name}:\")",
        "    for metric, value in result.metrics.items():",
        "        print(f\"  {metric}: {value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}